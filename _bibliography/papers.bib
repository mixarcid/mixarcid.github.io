---
---

@article{brocidiacono_bigbind_2022,
	title = {{BigBind}: Learning from Nonstructural Data for Structure-Based Virtual Screening},
	url = {https://chemrxiv.org/engage/chemrxiv/article-details/637e3b5094ff6027063cc956},
	doi = {10.26434/chemrxiv-2022-3qc9t},
	shorttitle = {{BigBind}},
	abstract = {Recent attempts at utilizing deep learning for structure-based virtual screening have focused on training models to predict binding affinity from protein-ligand complexes with known crystal structures. The {PDBbind} dataset is the current standard for training such models, but its small size (less than 20K binding affinity measurements) leads to models failing to generalize to new targets, and model performance is typically on par with those trained with only ligand information. The {CrossDocked} dataset expands binding pose data for protein-ligand complexes but does not introduce new affinity data. {ChEMBL}, on the other hand, contains a wealth of binding affinity information but contains no information about the binding poses. We introduce {BigBind}, a dataset that maps {ChEMBL} activity data to protein targets from {CrossDocked}. This dataset comprises 851K ligand binding affinities and 3D pocket structures. After augmenting this dataset with an equal number of putative inactives for each target, we train {BANANA} ({BAsic} {NeurAl} Network for binding Affinity) to classify actives from inactives. The resulting model achieved an {AUC} of 0.72 on {BigBind}â€™s test set, while a ligand-only model achieved an {AUC} of 0.64. Our model achieves competitive performance on the {LIT}-{PCBA} benchmark (median {EF}1\% 2.06) while running 16,000 times faster than molecular docking with {GNINA}. Notably, we achieve a state-of-the-art {EF}1\% of 4.95 when we use {BANANA} to filter out 90\% of the compounds prior to docking with {GNINA}. We hope that {BANANA} and future models trained on this dataset will prove useful for prospective virtual screening tasks.},
	author = {Brocidiacono, Michael and Francoeur, Paul and Aggarwal, Rishal and Popov, Konstantin and Koes, David and Tropsha, Alexander},
	urldate = {2022-11-28},
	date = {2022-11-28},
	year = {2022},
	langid = {english},
}

@misc{arcidiacono_molucinate_2021,
	title = {{MOLUCINATE}: A Generative Model for Molecules in 3D Space},
	url = {http://arxiv.org/abs/2109.15308},
	doi = {10.48550/arXiv.2109.15308},
	shorttitle = {{MOLUCINATE}},
	abstract = {Recent advances in machine learning have enabled generative models for both optimization and de novo generation of drug candidates with desired properties. Previous generative models have focused on producing {SMILES} strings or 2D molecular graphs, while attempts at producing molecules in 3D have focused on reinforcement learning ({RL}), distance matrices, and pure atom density grids. Here we present {MOLUCINATE} ({MOLecUlar} {ConvolutIoNal} {generATive} {modEl}), a novel architecture that simultaneously generates topological and 3D atom position information. We demonstrate the utility of this method by using it to optimize molecules for desired radius of gyration. In the future, this model can be used for more useful optimization such as binding affinity for a protein target.},
	number = {{arXiv}:2109.15308},
	publisher = {{arXiv}},
	author = {Arcidiacono, Michael and Koes, David Ryan},
	urldate = {2022-11-28},
	date = {2021-11-23},
	year = {2021},
	eprinttype = {arxiv},
	eprint = {2109.15308 [q-bio]},
	keywords = {Quantitative Biology - Quantitative Methods},
}
